# pyspark-ml-training-utils
Utilities for efficient distributed training of multiple ML models. Ideal for applications such as training independent models for ensembling or testing different algorithsm / hyperparameter sets. Distributes model training across nodes in a Spark cluster.
